<h1 id="assignment-1---supervised-learning-knn-and-backpropagation">Assignment 1 - Supervised learning: kNN and Backpropagation</h1>
<h2 id="overview-of-the-data">Overview of the data</h2>
<p>Looking at the data from a machine learning perspective we can observe how the data is compressed from 32x32 bitmap images to 64 features with the integer range 0..16. This means that we can create a hypercube feature space with 64 dimensions. This is a significantly dimensionally reduced feature space compared to 32x32 binary dimensions.</p>
<p>The pre processing of the data doesn't only reduce the number of dimensions, it also reduces the variance in small distortions.</p>
<h2 id="implementation-of-the-knn-algorithm">Implementation of the kNN algorithm</h2>
<h3 id="knn-without-cross-validation">kNN without cross-validation</h3>
<p>The implementation of kNN is fairly straight forward.</p>
<p>We iterate though all the cases in the test set and calculate the distance to each point in the training set. The result is then sorted in ascending order and the <code>k</code> first elements are counted in regards to what label they are assigned. The label with the most values are then picked to be assigned for the testing case we are currently processing. When no counted label is higher than another we pick the label with the data point which have the closest euclidean distance to the test case.</p>
<p>The result of our implementation of the kNN algorithm with k arbitrarily choose as 4 can be seen below.</p>
<p>Parameters: k = 4 Accuracy = 0.9710</p>
<pre><code>cM =

    99     0     0     0     0     0     0     0     0     0
     0    97     1     0     0     0     0     0     2     3
     0     0    97     0     0     0     0     0     0     1
     0     1     0    98     0     0     0     0     0     3
     0     1     0     0    96     0     0     0     0     2
     0     0     0     1     0   100     0     0     0     1
     1     0     0     0     0     0   100     0     0     0
     0     0     2     0     0     0     0   100     0     0
     0     1     0     0     1     0     0     0    96     2
     0     0     0     1     3     0     0     0     2    88</code></pre>
<div class="figure">
<img src="Supervised/kNN_simple.png" title="Result from kNN]" alt="Result from kNN" />
<p class="caption">Result from kNN</p>
</div>
<h3 id="knn-with-n-fold-cross-validation">kNN with n-fold cross validation</h3>
<p>For the cross validation version the n-fold cross validation algorithm was used to determine the best value for k. For all of the following results a n of 2 was used but he algorithm implementation allow for any value of n as long as it can evenly distribute the data set. Accuracy is used as the validation score in order to find the best value for k.</p>
<h4 id="data-set-1">Data set 1</h4>
<div class="figure">
<img src="Supervised/kNN_1_cv_score.png" title="CV scores" alt="Cross validation scores" />
<p class="caption">Cross validation scores</p>
</div>
<p>Best parameters: k = 1 Accuracy = 0.9900</p>
<div class="figure">
<img src="Supervised/kNN_1_cv.png" title="result" alt="OCR result" />
<p class="caption">OCR result</p>
</div>
<h4 id="data-set-2">Data set 2</h4>
<div class="figure">
<img src="Supervised/kNN_2_cv_score.png" title="CV scores" alt="Cross validation scores" />
<p class="caption">Cross validation scores</p>
</div>
<p>Best parameters: k = 1 Accuracy = 1</p>
<div class="figure">
<img src="Supervised/kNN_2_cv.png" title="result" alt="OCR result" />
<p class="caption">OCR result</p>
</div>
<h4 id="data-set-3">Data set 3</h4>
<div class="figure">
<img src="Supervised/kNN_3_cv_score.png" title="CV scores" alt="Cross validation scores" />
<p class="caption">Cross validation scores</p>
</div>
<p>Best parameters: k = 1 Accuracy = 1</p>
<div class="figure">
<img src="Supervised/kNN_3_cv.png" title="result" alt="OCR result" />
<p class="caption">OCR result</p>
</div>
<h4 id="data-set-4">Data set 4</h4>
<div class="figure">
<img src="Supervised/kNN_4_score.png" title="CV scores" alt="Cross validation scores" />
<p class="caption">Cross validation scores</p>
</div>
<p>Best parameters: k = 1 Accuracy = 0.9840</p>
<div class="figure">
<img src="Supervised/kNN_4_cv.png" title="result" alt="OCR result" />
<p class="caption">OCR result</p>
</div>
<ul>
<li><p>Explain how you selected the best k for each data set using CV and the result, include the accuracy and images of your results for each data set</p></li>
<li>A short summary of your backprop network implementation (single + multi)</li>
<li>Present the result from the backprop training and how you reached the accuracy criteria for each dataset. Motivate your choice of network for each dataset, then explain how you selected good values for the learning rate</li>
<li>Present the result, including images, of your example for a non-generalisable backprop solution. Explain why this example is non-generalisable</li>
<li><p>A final discussion and conclusion where you explain the difference between the performance of the different classifiers, Pros and cons etc.</p></li>
</ul>
